{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RACn8LMIwzan"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gFpyEubWyoL1"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "0KBuGS8Y0MBr",
    "outputId": "98e13318-9a5a-487e-b62d-8c46657105c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 2CD7-88B3\n",
      "\n",
      " Directory of C:\\Users\\KIIT\\projects\\cvpr\n",
      "\n",
      "29-10-2024  14:22    <DIR>          .\n",
      "16-10-2024  23:35    <DIR>          ..\n",
      "29-10-2024  14:17    <DIR>          .ipynb_checkpoints\n",
      "29-10-2024  14:17    <DIR>          class\n",
      "29-10-2024  14:17           114,506 CVPR_cbam_project.ipynb\n",
      "29-10-2024  14:21            53,768 hasan_1.jpg\n",
      "29-10-2024  14:21            19,871 hasan_2.jpg\n",
      "29-10-2024  14:21           234,210 manodeep.jpg\n",
      "               4 File(s)        422,355 bytes\n",
      "               4 Dir(s)  62,163,431,424 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic1 = cv2.imread(\"manodeep.jpg\")\n",
    "#pic1 = cv2.cvtColor(pic1, cv2.COLOR_BGR2GRAY)\n",
    "pic2 = cv2.imread(\"hasan_1.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((224, 224, 3), (224, 224, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic1 = cv2.resize(pic1,(224,224))\n",
    "pic2 = cv2.resize(pic2,(224,224))\n",
    "pic1.shape,pic2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {1:\"manodeep\" , 2:\"hasan\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B2Ud9aaC0PdH",
    "outputId": "2a84d4a4-b7e1-4df3-87bd-dc06076f0939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 224, 224, 128)        3584      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 128)        0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 128)                  0         ['max_pooling2d[0][0]']       \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " global_max_pooling2d (Glob  (None, 128)                  0         ['max_pooling2d[0][0]']       \n",
      " alMaxPooling2D)                                                                                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 1, 128)            0         ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 1, 128)            0         ['global_max_pooling2d[0][0]']\n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1, 1, 16)             2064      ['reshape[0][0]',             \n",
      "                                                                     'reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1, 1, 128)            2176      ['dense[0][0]',               \n",
      "                                                                     'dense[1][0]']               \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1, 1, 128)            0         ['dense_1[0][0]',             \n",
      "                                                                     'dense_1[1][0]']             \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 1, 1, 128)            0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 112, 112, 128)        0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'activation[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 112, 112, 1)          0         ['multiply[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 112, 112, 1)          0         ['multiply[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 112, 112, 2)          0         ['lambda[0][0]',              \n",
      "                                                                     'lambda_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 1)          99        ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 112, 112, 128)        0         ['multiply[0][0]',            \n",
      "                                                                     'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 64)         73792     ['multiply_1[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)           0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 64)                   0         ['max_pooling2d_1[0][0]']     \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Gl  (None, 64)                   0         ['max_pooling2d_1[0][0]']     \n",
      " obalMaxPooling2D)                                                                                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 1, 1, 64)             0         ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 1, 1, 64)             0         ['global_max_pooling2d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1, 1, 8)              520       ['reshape_2[0][0]',           \n",
      "                                                                     'reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1, 1, 64)             576       ['dense_2[0][0]',             \n",
      "                                                                     'dense_2[1][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 1, 1, 64)             0         ['dense_3[0][0]',             \n",
      "                                                                     'dense_3[1][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 1, 1, 64)             0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)       (None, 56, 56, 64)           0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'activation_1[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 56, 56, 1)            0         ['multiply_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 56, 56, 1)            0         ['multiply_2[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 56, 56, 2)            0         ['lambda_2[0][0]',            \n",
      " )                                                                   'lambda_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 1)            99        ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)       (None, 56, 56, 64)           0         ['multiply_2[0][0]',          \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 200704)               0         ['multiply_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  2569024   ['flatten[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 2)                    258       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25773408 (98.32 MB)\n",
      "Trainable params: 25773408 (98.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Channel Attention Module (CAM)\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel = input_feature.shape[-1]  # Get the number of channels\n",
    "\n",
    "    # Shared Dense layers\n",
    "    shared_layer_one = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal')\n",
    "    shared_layer_two = layers.Dense(channel, kernel_initializer='he_normal')\n",
    "\n",
    "    # Global Average Pooling\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    # Global Max Pooling\n",
    "    max_pool = layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    # Add & Activate (sigmoid)\n",
    "    cbam_feature = layers.Add()([avg_pool, max_pool])\n",
    "    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    return layers.Multiply()([input_feature, cbam_feature])  # Scale the input with attention weights\n",
    "\n",
    "# Spatial Attention Module (SAM)\n",
    "def spatial_attention(input_feature):\n",
    "    # Average Pooling & Max Pooling along the channel axis\n",
    "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_feature)\n",
    "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_feature)\n",
    "\n",
    "    # Concatenate along the last axis (channel axis)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "\n",
    "    # Apply a 7x7 Conv2D layer followed by sigmoid activation\n",
    "    cbam_feature = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding='same', activation='sigmoid', kernel_initializer='he_normal')(concat)\n",
    "\n",
    "    return layers.Multiply()([input_feature, cbam_feature])  # Scale input by spatial attention\n",
    "\n",
    "# CBAM Block (Combines both CAM and SAM)\n",
    "def cbam_block(input_feature, ratio=8):\n",
    "    # Apply Channel Attention Module (CAM)\n",
    "    x = channel_attention(input_feature, ratio)\n",
    "\n",
    "    # Apply Spatial Attention Module (SAM)\n",
    "    x = spatial_attention(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# CNN model with CBAM attention\n",
    "def create_cnn_with_attention(input_shape=(224, 224, 3), num_classes=2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial CNN Layers\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # CBAM Block after the first convolutional block\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Continue with CNN Layers\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Another CBAM Block\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Flatten and add Dense Layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Output layer for classification\n",
    "    class_output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the full model\n",
    "    model = models.Model(inputs=inputs, outputs=class_output)\n",
    "\n",
    "    return model'''\n",
    "\n",
    "# Create the CNN model with CBAM attention\n",
    "model = create_cnn_with_attention()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Example training dataset preparation (replace with actual dataset)\n",
    "# Assuming `train_dataset` is a tf.data.Dataset object\n",
    "# model.fit(train_dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "d3VqnDwY95D_",
    "outputId": "f008fc69-6630-4cd3-f4ed-eef35cdc11a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_38 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_39 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_22 (Functional)       (None, 128)                  2577315   ['input_38[0][0]',            \n",
      "                                                          0          'input_39[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_62 (Lambda)          (None, 1)                    0         ['model_22[0][0]',            \n",
      "                                                                     'model_22[1][0]']            \n",
      "                                                                                                  \n",
      " dense_84 (Dense)            (None, 1)                    2         ['lambda_62[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25773152 (98.32 MB)\n",
      "Trainable params: 25773152 (98.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6931 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.6926 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 0.6921 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 725ms/step - loss: 0.6916 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.6911 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 806ms/step - loss: 0.6906 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.6901 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.6896 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.6891 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.6886 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x208be147f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Define the base CNN model for feature extraction\n",
    "'''def create_base_cnn(input_shape=(224, 224, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu')  # Final embedding layer\n",
    "    ])\n",
    "    return model\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Channel Attention Module (CAM)\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel = input_feature.shape[-1]  # Get the number of channels\n",
    "\n",
    "    # Shared Dense layers\n",
    "    shared_layer_one = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal')\n",
    "    shared_layer_two = layers.Dense(channel, kernel_initializer='he_normal')\n",
    "\n",
    "    # Global Average Pooling\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    # Global Max Pooling\n",
    "    max_pool = layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    # Add & Activate (sigmoid)\n",
    "    cbam_feature = layers.Add()([avg_pool, max_pool])\n",
    "    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    return layers.Multiply()([input_feature, cbam_feature])  # Scale the input with attention weights\n",
    "\n",
    "# Spatial Attention Module (SAM)\n",
    "def spatial_attention(input_feature):\n",
    "    # Average Pooling & Max Pooling along the channel axis\n",
    "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_feature)\n",
    "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_feature)\n",
    "\n",
    "    # Concatenate along the last axis (channel axis)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "\n",
    "    # Apply a 7x7 Conv2D layer followed by sigmoid activation\n",
    "    cbam_feature = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding='same', activation='sigmoid', kernel_initializer='he_normal')(concat)\n",
    "\n",
    "    return layers.Multiply()([input_feature, cbam_feature])  # Scale input by spatial attention\n",
    "\n",
    "# CBAM Block (Combines both CAM and SAM)\n",
    "def cbam_block(input_feature, ratio=8):\n",
    "    # Apply Channel Attention Module (CAM)\n",
    "    x = channel_attention(input_feature, ratio)\n",
    "\n",
    "    # Apply Spatial Attention Module (SAM)\n",
    "    x = spatial_attention(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# CNN model with CBAM attention\n",
    "def create_cnn_with_attention(input_shape=(224, 224, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial CNN Layers\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # CBAM Block after the first convolutional block\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Continue with CNN Layers\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Another CBAM Block\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Flatten and add Dense Layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    '''# Output layer for classification\n",
    "    class_output = layers.Dense(num_classes, activation='softmax')(x)'''\n",
    "\n",
    "    # Create the full model\n",
    "    model = models.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the Euclidean distance function\n",
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "# Define the Siamese network\n",
    "def create_siamese_network(input_shape=(224, 224, 3)):\n",
    "    # Two inputs for the two branches\n",
    "    inputA = layers.Input(shape=input_shape)\n",
    "    inputB = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Shared CNN base model\n",
    "    base_model = create_cnn_with_attention(input_shape=( 224, 224, 3))\n",
    "\n",
    "    # Generate the feature vectors for both inputs\n",
    "    featsA = base_model(inputA)\n",
    "    featsB = base_model(inputB)\n",
    "\n",
    "    # Compute the Euclidean distance between the two feature vectors\n",
    "    distance = layers.Lambda(euclidean_distance)([featsA, featsB])\n",
    "\n",
    "    # Final layer to classify similarity: 0 (dissimilar) or 1 (similar)\n",
    "    output = layers.Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "    # Create the Siamese network model\n",
    "    model = models.Model(inputs=[inputA, inputB], outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the Siamese network\n",
    "siamese_model = create_siamese_network()\n",
    "\n",
    "# Compile the model\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "siamese_model.summary()\n",
    "\n",
    "# Example training dataset (replace with your actual dataset)\n",
    "# For Siamese networks, inputs are typically pairs of images with a label indicating similarity.\n",
    "# Assuming `train_pairs` is the input data in the format [(img1, img2), label].\n",
    "#labels = 1\n",
    "#train_pairs = [(pic2, pic1), label]# where label is 0 or 1.\n",
    "\n",
    "pic1 = cv2.imread(\"manodeep.jpg\")\n",
    "#pic1 = cv2.cvtColor(pic1, cv2.COLOR_BGR2GRAY)\n",
    "pic2 = cv2.imread(\"hasan_1.jpg\")\n",
    "\n",
    "\n",
    "pic1 = cv2.resize(pic1, (224, 224)) / 255.0  # Normalize and resize to match input shape\n",
    "pic2 = cv2.resize(pic2, (224, 224)) / 255.0\n",
    "'''pic1 = np.expand_dims(pic1, axis=0)  # Shape becomes (1, 224, 224, 3)\n",
    "pic2 = np.expand_dims(pic2, axis=0)  # Shape becomes (1, 224, 224, 3)'''\n",
    "# Create pairs of images as separate arrays\n",
    "img1_data = np.array([pic1,pic2])  # Wrap in array and add more pairs as needed\n",
    "img2_data = np.array([pic1,pic2])\n",
    "\n",
    "# Create labels as an array (binary values: 0 for dissimilar, 1 for similar)\n",
    "labels = np.array([1 , 1])  # For example, label as 1 (similar) or 0 (dissimilar)\n",
    "\n",
    "# Now train the model with arrays of image pairs and labels\n",
    "\n",
    "siamese_model.fit([img1_data, img2_data], labels, epochs=10)\n",
    "#siamese_model.fit([pic1, pic1], labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "4rKR5lhnAv_g",
    "outputId": "bddbcb46-56f4-4616-8c57-412bab2e3828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers, models, backend as K\\nfrom tensorflow.keras.datasets import cifar10\\nfrom sklearn.model_selection import train_test_split\\n\\n# Load and preprocess MNIST dataset\\ndef load_mnist_data():\\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\\n\\n    # Normalize the images to [0, 1] and expand dimensions for channels\\n    x_train = np.expand_dims(x_train / 255.0, axis=-1)\\n    x_test = np.expand_dims(x_test / 255.0, axis=-1)\\n\\n    return x_train, y_train, x_test, y_test\\nimport tensorflow as tf\\nfrom tensorflow.keras import layers, models\\n\\n# Channel Attention Module (CAM)\\ndef channel_attention(input_feature, ratio=8):\\n    channel = input_feature.shape[-1]  # Get the number of channels\\n\\n    # Shared Dense layers\\n    shared_layer_one = layers.Dense(channel // ratio, activation=\\'relu\\', kernel_initializer=\\'he_normal\\')\\n    shared_layer_two = layers.Dense(channel, kernel_initializer=\\'he_normal\\')\\n\\n    # Global Average Pooling\\n    avg_pool = layers.GlobalAveragePooling2D()(input_feature)\\n    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\\n    avg_pool = shared_layer_one(avg_pool)\\n    avg_pool = shared_layer_two(avg_pool)\\n\\n    # Global Max Pooling\\n    max_pool = layers.GlobalMaxPooling2D()(input_feature)\\n    max_pool = layers.Reshape((1, 1, channel))(max_pool)\\n    max_pool = shared_layer_one(max_pool)\\n    max_pool = shared_layer_two(max_pool)\\n\\n    # Add & Activate (sigmoid)\\n    cbam_feature = layers.Add()([avg_pool, max_pool])\\n    cbam_feature = layers.Activation(\\'sigmoid\\')(cbam_feature)\\n\\n    return layers.Multiply()([input_feature, cbam_feature])  # Scale the input with attention weights\\n\\n# Spatial Attention Module (SAM)\\ndef spatial_attention(input_feature):\\n    # Average Pooling & Max Pooling along the channel axis\\n    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_feature)\\n    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_feature)\\n\\n    # Concatenate along the last axis (channel axis)\\n    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\\n\\n    # Apply a 7x7 Conv2D layer followed by sigmoid activation\\n    cbam_feature = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding=\\'same\\', activation=\\'sigmoid\\', kernel_initializer=\\'he_normal\\')(concat)\\n\\n    return layers.Multiply()([input_feature, cbam_feature])  # Scale input by spatial attention\\n\\n# CBAM Block (Combines both CAM and SAM)\\ndef cbam_block(input_feature, ratio=8):\\n    # Apply Channel Attention Module (CAM)\\n    x = channel_attention(input_feature, ratio)\\n\\n    # Apply Spatial Attention Module (SAM)\\n    x = spatial_attention(x)\\n\\n    return x\\n\\n# CNN model with CBAM attention\\ndef create_cnn_with_attention(input_shape=(32, 32, 3), num_classes=10):\\n    inputs = layers.Input(shape=input_shape)\\n\\n    # Initial CNN Layers\\n    x = layers.Conv2D(32, (3, 3), activation=\\'relu\\', padding=\\'same\\')(inputs)\\n    x = layers.MaxPooling2D((2, 2))(x)\\n\\n    # CBAM Block after the first convolutional block\\n    x = cbam_block(x)\\n\\n    # Continue with CNN Layers\\n    x = layers.Conv2D(64, (3, 3), activation=\\'relu\\', padding=\\'same\\')(x)\\n    x = layers.MaxPooling2D((2, 2))(x)\\n\\n    # Another CBAM Block\\n    x = cbam_block(x)\\n\\n    # Flatten and add Dense Layers\\n    x = layers.Flatten()(x)\\n    x = layers.Dense(128, activation=\\'relu\\')(x)\\n\\n    # Output layer for classification\\n    class_output = layers.Dense(num_classes, activation=\\'softmax\\')(x)\\n\\n    # Create the full model\\n    model = models.Model(inputs=inputs, outputs=class_output)\\n\\n    return model\\n\\n\\n\\n# Example training dataset preparation (replace with actual dataset)\\n# Assuming `train_dataset` is a tf.data.Dataset object\\n# model.fit(train_dataset, epochs=10)\\n\\n# Create pairs of images for training Siamese network\\ndef create_pairs(x, y):\\n    pairs = []\\n    labels = []\\n    num_classes = len(np.unique(y))\\n    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\\n\\n    for idx in range(len(x)):\\n        current_image = x[idx]\\n        current_label = y[idx]\\n\\n        # Positive pair (same class)\\n        positive_idx = np.random.choice(digit_indices[current_label])\\n        positive_image = x[positive_idx]\\n\\n        pairs.append([current_image, positive_image])\\n        labels.append(1)  # Label for similar images is 1\\n\\n        # Negative pair (different class)\\n        negative_label = np.random.choice([i for i in range(num_classes) if i != current_label])\\n        negative_idx = np.random.choice(digit_indices[negative_label])\\n        negative_image = x[negative_idx]\\n\\n        pairs.append([current_image, negative_image])\\n        labels.append(0)  # Label for dissimilar images is 0\\n\\n    return np.array(pairs), np.array(labels)\\n\\n# Define the base CNN model for feature extraction\\ndef create_base_cnn(input_shape=(28, 28, 1)):\\n    model = models.Sequential([\\n        layers.Conv2D(32, (3, 3), activation=\\'relu\\', input_shape=input_shape),\\n        layers.MaxPooling2D(pool_size=(2, 2)),\\n        layers.Conv2D(64, (3, 3), activation=\\'relu\\'),\\n        layers.MaxPooling2D(pool_size=(2, 2)),\\n        layers.Conv2D(128, (3, 3), activation=\\'relu\\'),\\n        layers.Flatten(),\\n        layers.Dense(128, activation=\\'relu\\'),\\n        layers.Dense(64, activation=\\'relu\\')  # Final embedding layer\\n    ])\\n    return model\\n\\n# Define the Euclidean distance function\\ndef euclidean_distance(vectors):\\n    (featsA, featsB) = vectors\\n    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\\n    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\\n\\n# Define the Siamese network\\ndef create_siamese_network(input_shape=(28, 28, 1) , num_classes = 10):\\n    # Two inputs for the two branches\\n    inputA = layers.Input(shape=input_shape)\\n    inputB = layers.Input(shape=input_shape)\\n\\n    # Shared CNN base model\\n    #base_model = create_base_cnn(input_shape)\\n    base_model = create_cnn_with_attention(input_shape , num_classes)\\n    # Generate the feature vectors for both inputs\\n    featsA = base_model(inputA)\\n    featsB = base_model(inputB)\\n\\n    # Compute the Euclidean distance between the two feature vectors\\n    distance = layers.Lambda(euclidean_distance)([featsA, featsB])\\n\\n    # Final layer to classify similarity: 0 (dissimilar) or 1 (similar)\\n    output = layers.Dense(1, activation=\\'sigmoid\\')(distance)\\n\\n    # Create the Siamese network model\\n    model = models.Model(inputs=[inputA, inputB], outputs=output)\\n\\n    return model\\n\\n# Load the MNIST dataset\\nx_train, y_train, x_test, y_test = load_mnist_data()\\n\\n# Create pairs of images and their corresponding labels for training and testing\\ntrain_pairs, train_labels = create_pairs(x_train, y_train)\\ntest_pairs, test_labels = create_pairs(x_test, y_test)\\n\\n# Split pairs into two sets of inputs for the Siamese network\\ntrain_pair_1, train_pair_2 = train_pairs[:, 0], train_pairs[:, 1]\\ntest_pair_1, test_pair_2 = test_pairs[:, 0], test_pairs[:, 1]\\n\\n# Create the Siamese network model\\nsiamese_model = create_siamese_network()\\n\\n# Compile the model\\nsiamese_model.compile(optimizer=\\'adam\\', loss=\\'binary_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# Print model summary\\nsiamese_model.summary()\\n\\n# Train the Siamese network on the MNIST pairs\\nsiamese_model.fit([train_pair_1, train_pair_2], train_labels,\\n                  validation_data=([test_pair_1, test_pair_2], test_labels),\\n                  epochs=10, batch_size=64)\\n\\n# Evaluate the model\\nloss, accuracy = siamese_model.evaluate([test_pair_1, test_pair_2], test_labels)\\nprint(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "def load_mnist_data():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Normalize the images to [0, 1] and expand dimensions for channels\n",
    "    x_train = np.expand_dims(x_train / 255.0, axis=-1)\n",
    "    x_test = np.expand_dims(x_test / 255.0, axis=-1)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Channel Attention Module (CAM)\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel = input_feature.shape[-1]  # Get the number of channels\n",
    "\n",
    "    # Shared Dense layers\n",
    "    shared_layer_one = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal')\n",
    "    shared_layer_two = layers.Dense(channel, kernel_initializer='he_normal')\n",
    "\n",
    "    # Global Average Pooling\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    # Global Max Pooling\n",
    "    max_pool = layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    # Add & Activate (sigmoid)\n",
    "    cbam_feature = layers.Add()([avg_pool, max_pool])\n",
    "    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n",
    "\n",
    "    return layers.Multiply()([input_feature, cbam_feature])  # Scale the input with attention weights\n",
    "\n",
    "# Spatial Attention Module (SAM)\n",
    "def spatial_attention(input_feature):\n",
    "    # Average Pooling & Max Pooling along the channel axis\n",
    "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_feature)\n",
    "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_feature)\n",
    "\n",
    "    # Concatenate along the last axis (channel axis)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "\n",
    "    # Apply a 7x7 Conv2D layer followed by sigmoid activation\n",
    "    cbam_feature = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding='same', activation='sigmoid', kernel_initializer='he_normal')(concat)\n",
    "\n",
    "    return layers.Multiply()([input_feature, cbam_feature])  # Scale input by spatial attention\n",
    "\n",
    "# CBAM Block (Combines both CAM and SAM)\n",
    "def cbam_block(input_feature, ratio=8):\n",
    "    # Apply Channel Attention Module (CAM)\n",
    "    x = channel_attention(input_feature, ratio)\n",
    "\n",
    "    # Apply Spatial Attention Module (SAM)\n",
    "    x = spatial_attention(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# CNN model with CBAM attention\n",
    "def create_cnn_with_attention(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial CNN Layers\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # CBAM Block after the first convolutional block\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Continue with CNN Layers\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Another CBAM Block\n",
    "    x = cbam_block(x)\n",
    "\n",
    "    # Flatten and add Dense Layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Output layer for classification\n",
    "    class_output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the full model\n",
    "    model = models.Model(inputs=inputs, outputs=class_output)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Example training dataset preparation (replace with actual dataset)\n",
    "# Assuming `train_dataset` is a tf.data.Dataset object\n",
    "# model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Create pairs of images for training Siamese network\n",
    "def create_pairs(x, y):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    num_classes = len(np.unique(y))\n",
    "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "    for idx in range(len(x)):\n",
    "        current_image = x[idx]\n",
    "        current_label = y[idx]\n",
    "\n",
    "        # Positive pair (same class)\n",
    "        positive_idx = np.random.choice(digit_indices[current_label])\n",
    "        positive_image = x[positive_idx]\n",
    "\n",
    "        pairs.append([current_image, positive_image])\n",
    "        labels.append(1)  # Label for similar images is 1\n",
    "\n",
    "        # Negative pair (different class)\n",
    "        negative_label = np.random.choice([i for i in range(num_classes) if i != current_label])\n",
    "        negative_idx = np.random.choice(digit_indices[negative_label])\n",
    "        negative_image = x[negative_idx]\n",
    "\n",
    "        pairs.append([current_image, negative_image])\n",
    "        labels.append(0)  # Label for dissimilar images is 0\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "# Define the base CNN model for feature extraction\n",
    "def create_base_cnn(input_shape=(28, 28, 1)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu')  # Final embedding layer\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the Euclidean distance function\n",
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "# Define the Siamese network\n",
    "def create_siamese_network(input_shape=(28, 28, 1) , num_classes = 10):\n",
    "    # Two inputs for the two branches\n",
    "    inputA = layers.Input(shape=input_shape)\n",
    "    inputB = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Shared CNN base model\n",
    "    #base_model = create_base_cnn(input_shape)\n",
    "    base_model = create_cnn_with_attention(input_shape , num_classes)\n",
    "    # Generate the feature vectors for both inputs\n",
    "    featsA = base_model(inputA)\n",
    "    featsB = base_model(inputB)\n",
    "\n",
    "    # Compute the Euclidean distance between the two feature vectors\n",
    "    distance = layers.Lambda(euclidean_distance)([featsA, featsB])\n",
    "\n",
    "    # Final layer to classify similarity: 0 (dissimilar) or 1 (similar)\n",
    "    output = layers.Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "    # Create the Siamese network model\n",
    "    model = models.Model(inputs=[inputA, inputB], outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_mnist_data()\n",
    "\n",
    "# Create pairs of images and their corresponding labels for training and testing\n",
    "train_pairs, train_labels = create_pairs(x_train, y_train)\n",
    "test_pairs, test_labels = create_pairs(x_test, y_test)\n",
    "\n",
    "# Split pairs into two sets of inputs for the Siamese network\n",
    "train_pair_1, train_pair_2 = train_pairs[:, 0], train_pairs[:, 1]\n",
    "test_pair_1, test_pair_2 = test_pairs[:, 0], test_pairs[:, 1]\n",
    "\n",
    "# Create the Siamese network model\n",
    "siamese_model = create_siamese_network()\n",
    "\n",
    "# Compile the model\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "siamese_model.summary()\n",
    "\n",
    "# Train the Siamese network on the MNIST pairs\n",
    "siamese_model.fit([train_pair_1, train_pair_2], train_labels,\n",
    "                  validation_data=([test_pair_1, test_pair_2], test_labels),\n",
    "                  epochs=10, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = siamese_model.evaluate([test_pair_1, test_pair_2], test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "bzyviUwjAytb",
    "outputId": "84a00695-420a-456b-898e-734c18d9b780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Train the Siamese network on the MNIST pairs\\n\\n\\n# Evaluate the model\\nloss, accuracy = siamese_model.evaluate([test_pair_1, test_pair_2], test_labels)\\nprint(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Train the Siamese network on the MNIST pairs\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = siamese_model.evaluate([test_pair_1, test_pair_2], test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_2 (Functional)        (None, 2)                    2577340   ['input_5[0][0]',             \n",
      "                                                          8          'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)          (None, 1)                    0         ['model_2[0][0]',             \n",
      "                                                                     'model_2[1][0]']             \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 1)                    2         ['lambda_12[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25773410 (98.32 MB)\n",
      "Trainable params: 25773410 (98.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "J9mkIm7wBxmh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "The images are similar.\n"
     ]
    }
   ],
   "source": [
    "test_img1 = cv2.imread('hasan_1.jpg')\n",
    "test_img2 = cv2.imread('hasan_2.jpg')\n",
    "test_img1 = cv2.resize(test_img1, (224, 224)) / 255.0  # Scale pixel values to [0, 1]\n",
    "test_img2 = cv2.resize(test_img2, (224, 224)) / 255.0\n",
    "\n",
    "# Expand dimensions to simulate a batch of 1 sample per image\n",
    "test_img1 = np.expand_dims(test_img1, axis=0)  # Shape: (1, 224, 224, 3)\n",
    "test_img2 = np.expand_dims(test_img2, axis=0)  # Shape: (1, 224, 224, 3)\n",
    "\n",
    "# Make a similarity prediction\n",
    "similarity_score = siamese_model.predict([test_img1, test_img2])\n",
    "\n",
    "# Interpret the result\n",
    "if similarity_score[0][0] > 0.5:\n",
    "    print(\"The images are similar.\")\n",
    "else:\n",
    "    print(\"The images are dissimilar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1248/3750 [========>.....................] - ETA: 3:47 - loss: 0.6932 - accuracy: 0.4975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m siamese_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m siamese_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    114\u001b[0m     [train_pairs[:, \u001b[38;5;241m0\u001b[39m], train_pairs[:, \u001b[38;5;241m1\u001b[39m]], train_labels,\n\u001b[0;32m    115\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m([test_pairs[:, \u001b[38;5;241m0\u001b[39m], test_pairs[:, \u001b[38;5;241m1\u001b[39m]], test_labels),\n\u001b[0;32m    116\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m    117\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    118\u001b[0m )\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Test prediction on a test pair\u001b[39;00m\n\u001b[0;32m    121\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m siamese_model\u001b[38;5;241m.\u001b[39mpredict([test_pairs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], test_pairs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and prepare the MNIST data\n",
    "(input_train, label_train), (input_test, label_test) = mnist.load_data()\n",
    "input_train, input_test = input_train / 255.0, input_test / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Resize to fit model input (28, 28, 1) for grayscale images\n",
    "input_train = np.expand_dims(input_train, -1)\n",
    "input_test = np.expand_dims(input_test, -1)\n",
    "\n",
    "# Function to create pairs of images and labels (1 for similar, 0 for dissimilar)\n",
    "def create_pairs(images, labels, num_pairs=10000):\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "    num_classes = 10\n",
    "    digit_indices = [np.where(labels == i)[0] for i in range(num_classes)]\n",
    "\n",
    "    for _ in range(num_pairs):\n",
    "        # Select a random digit\n",
    "        digit = np.random.randint(0, num_classes)\n",
    "        idx1, idx2 = np.random.choice(digit_indices[digit], 2, replace=False)\n",
    "        # Add a similar pair\n",
    "        pairs += [[images[idx1], images[idx2]]]\n",
    "        pair_labels += [1]\n",
    "\n",
    "        # Add a dissimilar pair\n",
    "        other_digit = (digit + np.random.randint(1, num_classes)) % num_classes\n",
    "        idx1, idx2 = np.random.choice(digit_indices[digit], 1), np.random.choice(digit_indices[other_digit], 1)\n",
    "        pairs += [[images[idx1][0], images[idx2][0]]]\n",
    "        pair_labels += [0]\n",
    "\n",
    "    return np.array(pairs), np.array(pair_labels)\n",
    "\n",
    "# Generate training and testing pairs\n",
    "train_pairs, train_labels = create_pairs(input_train, label_train, num_pairs=60000)\n",
    "test_pairs, test_labels = create_pairs(input_test, label_test, num_pairs=10000)\n",
    "\n",
    "# Channel Attention Module (CAM)\n",
    "def channel_attention(input_feature, ratio=8):\n",
    "    channel = input_feature.shape[-1]\n",
    "    shared_layer_one = layers.Dense(channel // ratio, activation='relu', kernel_initializer='he_normal')\n",
    "    shared_layer_two = layers.Dense(channel, kernel_initializer='he_normal')\n",
    "\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    cbam_feature = layers.Add()([avg_pool, max_pool])\n",
    "    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n",
    "    return layers.Multiply()([input_feature, cbam_feature])\n",
    "\n",
    "# Spatial Attention Module (SAM)\n",
    "def spatial_attention(input_feature):\n",
    "    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_feature)\n",
    "    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_feature)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "    cbam_feature = layers.Conv2D(filters=1, kernel_size=7, strides=1, padding='same', activation='sigmoid', kernel_initializer='he_normal')(concat)\n",
    "    return layers.Multiply()([input_feature, cbam_feature])\n",
    "\n",
    "# CBAM Block (Combines CAM and SAM)\n",
    "def cbam_block(input_feature, ratio=8):\n",
    "    x = channel_attention(input_feature, ratio)\n",
    "    x = spatial_attention(x)\n",
    "    return x\n",
    "\n",
    "# Define the CNN model with CBAM attention for MNIST\n",
    "def create_cnn_with_attention(input_shape=(28, 28, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = cbam_block(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = cbam_block(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    return models.Model(inputs, x)\n",
    "\n",
    "# Define Euclidean distance function\n",
    "def euclidean_distance(vectors):\n",
    "    featsA, featsB = vectors\n",
    "    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "# Define Siamese model with CBAM CNN base\n",
    "def create_siamese_network(input_shape=(28, 28, 1)):\n",
    "    inputA = layers.Input(shape=input_shape)\n",
    "    inputB = layers.Input(shape=input_shape)\n",
    "\n",
    "    base_cnn = create_cnn_with_attention(input_shape)\n",
    "    featsA = base_cnn(inputA)\n",
    "    featsB = base_cnn(inputB)\n",
    "\n",
    "    distance = layers.Lambda(euclidean_distance)([featsA, featsB])\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "    return models.Model(inputs=[inputA, inputB], outputs=output)\n",
    "\n",
    "# Compile and train the model\n",
    "siamese_model = create_siamese_network()\n",
    "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "siamese_model.fit(\n",
    "    [train_pairs[:, 0], train_pairs[:, 1]], train_labels,\n",
    "    validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels),\n",
    "    batch_size=32,\n",
    "    epochs=2\n",
    ")\n",
    "\n",
    "# Test prediction on a test pair\n",
    "test_pred = siamese_model.predict([test_pairs[0:1, 0], test_pairs[0:1, 1]])\n",
    "print(\"Similarity score:\", test_pred[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
